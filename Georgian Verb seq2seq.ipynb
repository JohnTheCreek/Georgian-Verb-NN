{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f093e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all relevant libraries for preprocessing and gensim \n",
    "import os \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "um = pd.read_csv(r\"C:\\Users\\Home\\Desktop\\Python Scripts\\kat-master\\um_features.csv\")\n",
    "um.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of Georgian chars\n",
    "georgian_chars = [\n",
    "    'ა', \n",
    "    'ბ', \n",
    "    'გ', \n",
    "    'დ', \n",
    "    'ე', \n",
    "    'ვ', \n",
    "    'ზ', \n",
    "    'თ', \n",
    "    'ი', \n",
    "    'კ', \n",
    "    'ლ', \n",
    "    'მ', \n",
    "    'ნ', \n",
    "    'ო', \n",
    "    'პ', \n",
    "    'ჟ', \n",
    "    'რ', \n",
    "    'ს', \n",
    "    'ტ', \n",
    "    'უ', \n",
    "    'ფ', \n",
    "    'ქ', \n",
    "    'ღ', \n",
    "    'ყ', \n",
    "    'შ', \n",
    "    'ჩ', \n",
    "    'ც', \n",
    "    'ძ', \n",
    "    'წ', \n",
    "    'ჭ', \n",
    "    'ხ', \n",
    "    'ჯ', \n",
    "    'ჰ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab dict with chars as keys and indices as values\n",
    "char2idx = {\n",
    "    \"<bos>\": 0,\n",
    "    \"<eos>\": 1,\n",
    "     **{c: i+2 for i, c in enumerate(sorted(georgian_chars))}\n",
    "}\n",
    "\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9935fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab dict with tags from the data as keys and indices as values\n",
    "## first seperate the tag column by the delimiter and make a list of all tags\n",
    "um['tag'] = um['tag'].str.split(';')\n",
    "um[\"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "um['tag'] = um['tag'].apply(lambda tags: [tag for tag in tags if tag != \"V\"])\n",
    "um[\"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all tags\n",
    "all_tags = []\n",
    "for tags in um['tag']:\n",
    "    all_tags.extend(tags)\n",
    "all_tags\n",
    "# remove duplicates from the list of tags\n",
    "all_tags = list(set(all_tags))\n",
    "# make a dict with tags as keys and indices as values\n",
    "tag2idx = {\n",
    "    tag: i+0 for i, tag in enumerate(sorted(all_tags))\n",
    "}\n",
    "\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the lemma column by characters and make a list of all lemmas\n",
    "um['lemma'] = um['lemma'].str.split('')\n",
    "# strip empty strings from the list of lemmas\n",
    "um['lemma'] = um['lemma'].apply(lambda lemmas: [lemma for lemma in lemmas if lemma != \"\"])\n",
    "um['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    tokens = [\"<bos>\"]\n",
    "    tokens.extend(row['lemma']) \n",
    "    tokens.extend(row['tag'])\n",
    "    tokens.append(\"<eos>\")\n",
    "    return tokens\n",
    "\n",
    "um['tokens'] = um.apply(tokenize, axis=1)\n",
    "um['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build one unified vocab for X\n",
    "symbols = ['bos', 'eos'] + sorted(georgian_chars) + sorted(all_tags)\n",
    "token2idx = {sym: i for i, sym in enumerate(symbols)}\n",
    "token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddd877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in target data\n",
    "target = pd.read_csv(r\"C:\\Users\\Home\\Desktop\\Python Scripts\\kat-master\\um_target.csv\")\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ee30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_target(row):\n",
    "    tokens_target = [\"<bos>\"]\n",
    "    tokens_target.extend(row['form']) \n",
    "    tokens_target.append(\"<eos>\")\n",
    "    return tokens_target\n",
    "# apply the function to the target data\n",
    "target['tokens'] = target.apply(tokenize_target, axis=1)\n",
    "target['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d793727",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model variables \n",
    "X = um['tokens'].values\n",
    "y = target['tokens'].values\n",
    "# check the data\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f93d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3236daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries for the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the dataset and dataloader\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be86514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ead92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.embedding(x).unsqueeze(0)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61265c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement seq2seq model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[1]\n",
    "        batch_size = trg.shape[0]\n",
    "        output_dim = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        x = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1) \n",
    "            x = trg[:, t] if random.random() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
